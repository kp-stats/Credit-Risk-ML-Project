{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1baebe88",
   "metadata": {},
   "source": [
    "<h1><center>Credit Risk Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929b0cd6",
   "metadata": {},
   "source": [
    "<h3>Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a019000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, cross_val_score,cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\\\n",
    ",recall_score,precision_score,f1_score\n",
    "from scipy.stats import f_oneway\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9fbe3f",
   "metadata": {},
   "source": [
    "<h3>Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646b2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=pd.read_excel(\"E:/ames_prediction/case_study1.xlsx\")\n",
    "a2=pd.read_excel(\"E:/ames_prediction/case_study2.xlsx\")\n",
    "\n",
    "df1 = a1.copy()\n",
    "df2 = a2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a3c9f5",
   "metadata": {},
   "source": [
    "<h3> Removing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196a45a",
   "metadata": {},
   "source": [
    "Nulls in our dataset were denoted by -99999<br>\n",
    "Nulls were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e2060904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]\n",
    "columns_to_be_removed = []\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
    "        columns_to_be_removed .append(i)\n",
    "df2 = df2.drop(columns_to_be_removed, axis =1)\n",
    "for i in df2.columns:\n",
    "    df2 = df2.loc[ df2[i] != -99999 ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c584822",
   "metadata": {},
   "source": [
    "<h3>Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc3817",
   "metadata": {},
   "source": [
    "Checking common column names to merge the two dataframes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0360a55b",
   "metadata": {},
   "source": [
    "for i in list(df1.columns):\n",
    "    if i in list(df2.columns):\n",
    "        print (i)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3cbb3",
   "metadata": {},
   "source": [
    "PROSPECTID is the common column<br>\n",
    "To Merge the two dataframes , we use inner join so that no nulls are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "053100ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd. merge ( df1, df2, how ='inner', left_on = ['PROSPECTID'], right_on = ['PROSPECTID'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f599db",
   "metadata": {},
   "source": [
    "We check how many columns are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "401034d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS\n",
      "EDUCATION\n",
      "GENDER\n",
      "last_prod_enq2\n",
      "first_prod_enq2\n",
      "Approved_Flag\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff41c59c",
   "metadata": {},
   "source": [
    "<h2>Feature Selection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7520ad",
   "metadata": {},
   "source": [
    "We apply the Chi-square test to find the degree of association between the categorical features and response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a24902",
   "metadata": {},
   "source": [
    "Ho: There is no association between the variables<br>\n",
    "H1: There is association between the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6616920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --- 3.578180861038862e-233\n",
      "EDUCATION --- 2.6942265249737532e-30\n",
      "GENDER --- 1.907936100186563e-05\n",
      "last_prod_enq2 --- 0.0\n",
      "first_prod_enq2 --- 7.84997610555419e-287\n"
     ]
    }
   ],
   "source": [
    "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i, '---', pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263c4ab2",
   "metadata": {},
   "source": [
    "Since all the categorical features have pval <0.05, we reject H0 at 5% level of significance and conclude that all categorical variable are associated with approved flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd169b5",
   "metadata": {},
   "source": [
    "We calculate VIF to check for Multicollinearity in numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c39c5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID','Approved_Flag']:\n",
    "        numeric_columns.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee658bb",
   "metadata": {},
   "source": [
    "VIF sequentially check<br>\n",
    "We remove the variables with VIF >6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "454636bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n",
      "0 --- inf\n",
      "0 --- 11.320180023967996\n",
      "0 --- 8.363698035000336\n",
      "0 --- 6.520647877790928\n",
      "0 --- 5.149501618212625\n",
      "1 --- 2.611111040579735\n",
      "2 --- inf\n",
      "2 --- 1788.7926256209232\n",
      "2 --- 8.601028256477228\n",
      "2 --- 3.8328007921530785\n",
      "3 --- 6.099653381646727\n",
      "3 --- 5.581352009642766\n",
      "4 --- 1.985584353098778\n",
      "5 --- inf\n",
      "5 --- 4.809538302819343\n",
      "6 --- 23.270628983464636\n",
      "6 --- 30.595522588100053\n",
      "6 --- 4.384346405965583\n",
      "7 --- 3.064658415523423\n",
      "8 --- 2.898639771299251\n",
      "9 --- 4.377876915347324\n",
      "10 --- 2.2078535836958433\n",
      "11 --- 4.916914200506864\n",
      "12 --- 5.214702030064725\n",
      "13 --- 3.3861625024231476\n",
      "14 --- 7.840583309478997\n",
      "14 --- 5.255034641721438\n",
      "15 --- inf\n",
      "15 --- 7.380634506427232\n",
      "15 --- 1.421005001517573\n",
      "16 --- 8.083255010190323\n",
      "16 --- 1.624122752404011\n",
      "17 --- 7.257811920140003\n",
      "17 --- 15.59624383268298\n",
      "17 --- 1.825857047132431\n",
      "18 --- 1.5080839450032664\n",
      "19 --- 2.172088834824577\n",
      "20 --- 2.623397553527229\n",
      "21 --- 2.2959970812106167\n",
      "22 --- 7.360578319196446\n",
      "22 --- 2.1602387773102554\n",
      "23 --- 2.8686288267891467\n",
      "24 --- 6.458218003637277\n",
      "24 --- 2.8474118865638247\n",
      "25 --- 4.753198156284083\n",
      "26 --- 16.227354755948223\n",
      "26 --- 6.424377256363877\n",
      "26 --- 8.887080381808687\n",
      "26 --- 2.3804746142952653\n",
      "27 --- 8.609513476514548\n",
      "27 --- 13.06755093547673\n",
      "27 --- 3.5000400566546555\n",
      "28 --- 1.9087955874813773\n",
      "29 --- 17.006562234161628\n",
      "29 --- 10.730485153719197\n",
      "29 --- 2.3538497522950275\n",
      "30 --- 22.104855915136433\n",
      "30 --- 2.7971639638512915\n",
      "31 --- 3.424171203217697\n",
      "32 --- 10.175021454450922\n",
      "32 --- 6.408710354561292\n",
      "32 --- 1.0011511962625619\n",
      "33 --- 3.069197305397274\n",
      "34 --- 2.8091261600643724\n",
      "35 --- 20.249538381980678\n",
      "35 --- 15.864576541593774\n",
      "35 --- 1.833164974053215\n",
      "36 --- 1.5680839909542044\n",
      "37 --- 1.9307572353811682\n",
      "38 --- 4.331265056645249\n",
      "39 --- 9.390334396150173\n"
     ]
    }
   ],
   "source": [
    "vif_data = df[numeric_columns]\n",
    "total_columns = vif_data.shape[1]\n",
    "columns_to_be_kept = []\n",
    "column_index = 0\n",
    "\n",
    "for i in range (0,total_columns):    \n",
    "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
    "    print (column_index,'---',vif_value)\n",
    "    if vif_value <= 6:\n",
    "        columns_to_be_kept.append( numeric_columns[i] )\n",
    "        column_index = column_index+1\n",
    "    else:\n",
    "        vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1b418cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 72 Variables, 39 are left\n"
     ]
    }
   ],
   "source": [
    "print(f\"Out of {total_columns} Variables, {len(columns_to_be_kept)} are left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdeb9c9",
   "metadata": {},
   "source": [
    "Using Anova to find association between the numerical features and Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b7f34def",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_kept_numerical = []\n",
    "\n",
    "for i in columns_to_be_kept:\n",
    "    a = list(df[i])  \n",
    "    b = list(df['Approved_Flag'])  \n",
    "    \n",
    "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "\n",
    "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488b747",
   "metadata": {},
   "source": [
    "feature selection is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e40fd5",
   "metadata": {},
   "source": [
    "<h4>listing all the final features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a320dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1291649",
   "metadata": {},
   "source": [
    "<h3> Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d0e23",
   "metadata": {},
   "source": [
    "Label encoding for the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4e0b64f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PL', 'ConsumerLoan', 'others', 'AL', 'HL', 'CC'], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MARITALSTATUS'].unique()    \n",
    "df['EDUCATION'].unique()\n",
    "df['GENDER'].unique()\n",
    "df['last_prod_enq2'].unique()\n",
    "df['first_prod_enq2'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a41a0",
   "metadata": {},
   "source": [
    "Ordinal feature -- EDUCATION<br>\n",
    "SSC            : 1<br>\n",
    "12TH           : 2<br>\n",
    "GRADUATE       : 3<br>\n",
    "UNDER GRADUATE : 3<br>\n",
    "POST-GRADUATE  : 4<br>\n",
    "OTHERS         : 1<br>\n",
    "PROFESSIONAL   : 3<br><br>\n",
    "\n",
    "Others has to be verified by the business end user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6de5e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
    "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
    "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "14ec0e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 43 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   pct_tl_open_L6M            42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M          42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M         42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M         42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt            42064 non-null  int64  \n",
      " 5   CC_TL                      42064 non-null  int64  \n",
      " 6   Home_TL                    42064 non-null  int64  \n",
      " 7   PL_TL                      42064 non-null  int64  \n",
      " 8   Secured_TL                 42064 non-null  int64  \n",
      " 9   Unsecured_TL               42064 non-null  int64  \n",
      " 10  Other_TL                   42064 non-null  int64  \n",
      " 11  Age_Oldest_TL              42064 non-null  int64  \n",
      " 12  Age_Newest_TL              42064 non-null  int64  \n",
      " 13  time_since_recent_payment  42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq  42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts          42064 non-null  int64  \n",
      " 16  num_times_60p_dpd          42064 non-null  int64  \n",
      " 17  num_std_12mts              42064 non-null  int64  \n",
      " 18  num_sub                    42064 non-null  int64  \n",
      " 19  num_sub_6mts               42064 non-null  int64  \n",
      " 20  num_sub_12mts              42064 non-null  int64  \n",
      " 21  num_dbt                    42064 non-null  int64  \n",
      " 22  num_dbt_12mts              42064 non-null  int64  \n",
      " 23  num_lss                    42064 non-null  int64  \n",
      " 24  recent_level_of_deliq      42064 non-null  int64  \n",
      " 25  CC_enq_L12m                42064 non-null  int64  \n",
      " 26  PL_enq_L12m                42064 non-null  int64  \n",
      " 27  time_since_recent_enq      42064 non-null  int64  \n",
      " 28  enq_L3m                    42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME           42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr        42064 non-null  int64  \n",
      " 31  CC_Flag                    42064 non-null  int64  \n",
      " 32  PL_Flag                    42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever     42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever     42064 non-null  float64\n",
      " 35  HL_Flag                    42064 non-null  int64  \n",
      " 36  GL_Flag                    42064 non-null  int64  \n",
      " 37  MARITALSTATUS              42064 non-null  object \n",
      " 38  EDUCATION                  42064 non-null  int64  \n",
      " 39  GENDER                     42064 non-null  object \n",
      " 40  last_prod_enq2             42064 non-null  object \n",
      " 41  first_prod_enq2            42064 non-null  object \n",
      " 42  Approved_Flag              42064 non-null  object \n",
      "dtypes: float64(5), int64(33), object(5)\n",
      "memory usage: 13.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df['EDUCATION'].value_counts()\n",
    "df['EDUCATION'] = df['EDUCATION'].astype('int64')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f05bc7",
   "metadata": {},
   "source": [
    "Creating dummy variables for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e6e0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   pct_tl_open_L6M               42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M             42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M            42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M            42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt               42064 non-null  int64  \n",
      " 5   CC_TL                         42064 non-null  int64  \n",
      " 6   Home_TL                       42064 non-null  int64  \n",
      " 7   PL_TL                         42064 non-null  int64  \n",
      " 8   Secured_TL                    42064 non-null  int64  \n",
      " 9   Unsecured_TL                  42064 non-null  int64  \n",
      " 10  Other_TL                      42064 non-null  int64  \n",
      " 11  Age_Oldest_TL                 42064 non-null  int64  \n",
      " 12  Age_Newest_TL                 42064 non-null  int64  \n",
      " 13  time_since_recent_payment     42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq     42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts             42064 non-null  int64  \n",
      " 16  num_times_60p_dpd             42064 non-null  int64  \n",
      " 17  num_std_12mts                 42064 non-null  int64  \n",
      " 18  num_sub                       42064 non-null  int64  \n",
      " 19  num_sub_6mts                  42064 non-null  int64  \n",
      " 20  num_sub_12mts                 42064 non-null  int64  \n",
      " 21  num_dbt                       42064 non-null  int64  \n",
      " 22  num_dbt_12mts                 42064 non-null  int64  \n",
      " 23  num_lss                       42064 non-null  int64  \n",
      " 24  recent_level_of_deliq         42064 non-null  int64  \n",
      " 25  CC_enq_L12m                   42064 non-null  int64  \n",
      " 26  PL_enq_L12m                   42064 non-null  int64  \n",
      " 27  time_since_recent_enq         42064 non-null  int64  \n",
      " 28  enq_L3m                       42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME              42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr           42064 non-null  int64  \n",
      " 31  CC_Flag                       42064 non-null  int64  \n",
      " 32  PL_Flag                       42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
      " 35  HL_Flag                       42064 non-null  int64  \n",
      " 36  GL_Flag                       42064 non-null  int64  \n",
      " 37  EDUCATION                     42064 non-null  int64  \n",
      " 38  Approved_Flag                 42064 non-null  object \n",
      " 39  MARITALSTATUS_Married         42064 non-null  bool   \n",
      " 40  MARITALSTATUS_Single          42064 non-null  bool   \n",
      " 41  GENDER_F                      42064 non-null  bool   \n",
      " 42  GENDER_M                      42064 non-null  bool   \n",
      " 43  last_prod_enq2_AL             42064 non-null  bool   \n",
      " 44  last_prod_enq2_CC             42064 non-null  bool   \n",
      " 45  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
      " 46  last_prod_enq2_HL             42064 non-null  bool   \n",
      " 47  last_prod_enq2_PL             42064 non-null  bool   \n",
      " 48  last_prod_enq2_others         42064 non-null  bool   \n",
      " 49  first_prod_enq2_AL            42064 non-null  bool   \n",
      " 50  first_prod_enq2_CC            42064 non-null  bool   \n",
      " 51  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
      " 52  first_prod_enq2_HL            42064 non-null  bool   \n",
      " 53  first_prod_enq2_PL            42064 non-null  bool   \n",
      " 54  first_prod_enq2_others        42064 non-null  bool   \n",
      "dtypes: bool(16), float64(5), int64(33), object(1)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])\n",
    "for i in df_encoded.select_dtypes(include=object).columns[:-1]:\n",
    "    df_encoded[i] = df_encoded[i].astype(int)\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac43663",
   "metadata": {},
   "source": [
    "<h4>Splitting into separate feature variable and Label variable</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f67b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7ff1b",
   "metadata": {},
   "source": [
    "<h4>label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc917c44",
   "metadata": {},
   "source": [
    "<h4>Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2fad19",
   "metadata": {},
   "source": [
    "We split data into Train set and Test set according to 80-20 scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c5d91ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f06cf6",
   "metadata": {},
   "source": [
    "<h3>Machine Learning model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a0827",
   "metadata": {},
   "source": [
    "<h4>Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "80ae9387",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "accuracy          0.72\n",
      "f1_macro          0.63\n",
      "precision_macro   0.63\n",
      "recall_macro      0.63\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "scoring=[\"accuracy\",\"f1_macro\",\"precision_macro\",\"recall_macro\"]\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "cv_scores = pd.DataFrame(cross_validate(dt_model, x_train, y_train, cv=5,scoring=scoring))\n",
    "cv_scores.drop(columns=[\"fit_time\",\"score_time\"],inplace=True)\n",
    "cv_scores.columns=scoring\n",
    "\n",
    "print(f\"Cross-validation scores:\\n{cv_scores.mean().to_string()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076dacd",
   "metadata": {},
   "source": [
    "<h4>Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7566f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "accuracy          0.77\n",
      "f1_macro          0.66\n",
      "precision_macro   0.71\n",
      "recall_macro      0.64\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "\n",
    "scoring=[\"accuracy\",\"f1_macro\",\"precision_macro\",\"recall_macro\"]\n",
    "\n",
    "cv_scores = pd.DataFrame(cross_validate(rf_classifier, x_train, y_train, cv=5,scoring=scoring))\n",
    "cv_scores.drop(columns=[\"fit_time\",\"score_time\"],inplace=True)\n",
    "cv_scores.columns=scoring\n",
    "\n",
    "print(f\"Cross-validation scores:\\n{cv_scores.mean().to_string()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178d4db",
   "metadata": {},
   "source": [
    "<h4>xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a1519f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "accuracy          0.77\n",
      "f1_macro          0.68\n",
      "precision_macro   0.70\n",
      "recall_macro      0.67\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "scoring=[\"accuracy\",\"f1_macro\",\"precision_macro\",\"recall_macro\"]\n",
    "\n",
    "cv_scores = pd.DataFrame(cross_validate(xgb_classifier, x_train, y_train, cv=5,scoring=scoring))\n",
    "cv_scores.drop(columns=[\"fit_time\",\"score_time\"],inplace=True)\n",
    "cv_scores.columns=scoring\n",
    "\n",
    "print(f\"Cross-validation scores:\\n{cv_scores.mean().to_string()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43561941",
   "metadata": {},
   "source": [
    "xgboost is giving me best results<br><br>\n",
    "We will further finetune it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d4336",
   "metadata": {},
   "source": [
    "<h3>Hyperparameter tuning in xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9aa6d264",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_class=4,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [1, 10, 100],\n",
       "                         &#x27;colsample_bytree&#x27;: [0.1, 0.3, 0.7],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 6, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_class=4,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [1, 10, 100],\n",
       "                         &#x27;colsample_bytree&#x27;: [0.1, 0.3, 0.7],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 6, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=4,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=4,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_class=4,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'alpha': [1, 10, 100],\n",
       "                         'colsample_bytree': [0.1, 0.3, 0.7],\n",
       "                         'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 6, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "param_grid = {\n",
    "   'colsample_bytree': [0.1, 0.3, 0.7],\n",
    "   'learning_rate'   : [0.01, 0.1,0.2],\n",
    "   'max_depth'       : [3,6,10],\n",
    "   'alpha'           : [1, 10, 100],\n",
    "   'n_estimators'    : [100,200,300]\n",
    " }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2264fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1, 'colsample_bytree': 0.7, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e5432",
   "metadata": {},
   "source": [
    "<h4>Best Hyperparameters: {'alpha': 1, 'colsample_bytree': 0.7, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6a8f6",
   "metadata": {},
   "source": [
    "<h4>Evaluate the model with the best hyperparameters on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f7782615",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ed69697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.849615806805708\n",
      "Recall: 0.7633136094674556\n",
      "F1 Score: 0.8041558441558442\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8176901605024425\n",
      "Recall: 0.9290386521308226\n",
      "F1 Score: 0.8698153474993041\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.46578947368421053\n",
      "Recall: 0.26716981132075474\n",
      "F1 Score: 0.339568345323741\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7435643564356436\n",
      "Recall: 0.7298347910592808\n",
      "F1 Score: 0.7366356056890633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=best_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239fd58",
   "metadata": {},
   "source": [
    "<h4> FInal Accuracy of our model is 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42323c94",
   "metadata": {},
   "source": [
    "<h4> Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e035325",
   "metadata": {},
   "source": [
    "Based on risk appetite of the bank, we will suggest P1,P2,P3,P4 to the business end user"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
